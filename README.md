# ü¶† Tri-Modal COVID-19 Diagnosis: Vision, Audio & Language (WIP)

> **Proyecto de Investigaci√≥n Avanzada:** Arquitectura Trimodal que integra Radiograf√≠as, Biomarcadores Ac√∫sticos (Tos) y Narrativa Cl√≠nica.

![Status](https://img.shields.io/badge/Status-Work%20In%20Progress%20(WIP)-yellow?style=flat-square&logo=git)
![Stage](https://img.shields.io/badge/Stage-Data%20Pipeline%20%26%20Architecture-orange?style=flat-square)
![Innovation](https://img.shields.io/badge/Tech-Synthetic%20Data%20Gen%20(LLM)-blue?style=flat-square)
![Stack](https://img.shields.io/badge/Stack-PyTorch%20%7C%20Transformers%20%7C%20Librosa-lightgrey?style=flat-square)

## üî≠ Visi√≥n y Desaf√≠o
El diagn√≥stico m√©dico humano es inherentemente multimodal. Un m√©dico no solo mira una radiograf√≠a; tambi√©n **escucha** la tos del paciente e **interpreta** su relato de s√≠ntomas.

Este proyecto busca replicar ese proceso hol√≠stico mediante una arquitectura de Deep Learning de **fusi√≥n tard√≠a** que integra tres fuentes de datos disjuntas:
1.  **Visi√≥n (Image):** Rayos X de T√≥rax (Detecci√≥n de neumon√≠a/vidrio esmerilado).
2.  **Audio (Signal):** Grabaciones de tos forzada (An√°lisis espectral de frecuencias).
3.  **Lenguaje (NLP):** Di√°logos paciente-m√©dico (An√°lisis sem√°ntico de s√≠ntomas).

## ‚öôÔ∏è Metodolog√≠a Definida (Pipeline)

El proyecto sigue una metodolog√≠a rigurosa documentada en el notebook principal (`lab_03_IA.ipynb`), estructurada en tres fases cr√≠ticas:

### 1. Fase de Texto: Generaci√≥n Sint√©tica con LLMs ü§ñ
* **Problema:** Escasez de datasets p√∫blicos con transcripciones reales de anamnesis (entrevistas cl√≠nicas) de COVID-19.
* **Soluci√≥n Innovadora:** Implementaci√≥n de un pipeline de **Generaci√≥n de Datos Sint√©ticos** utilizando APIs de LLMs (Large Language Models).
* **Ingenier√≠a del Script:**
    * **Batch Processing:** Generaci√≥n iterativa de di√°logos con manejo de `rate limits` (pausas estrat√©gicas para no saturar la API).
    * **Prompt Engineering:** Dise√±o de prompts para simular variaciones ling√º√≠sticas (pacientes ansiosos, descriptivos, breves).
    * **Class Balancing:** Control program√°tico para asegurar un 50/50 de casos Positivos/Negativos en el CSV de salida.
    * **Persistencia:** Guardado autom√°tico y barajado (`shuffle`) del dataset para evitar sesgos de orden.

### 2. Fase de Audio: Procesamiento Espectral üé§
* **Fuente:** Datasets de investigaci√≥n ac√∫stica (Coswara/DiCOVA).
* **T√©cnica:** Transformaci√≥n de audio raw (`.wav`) a representaciones visuales mediante **Mel-Spectrograms**.
* **Objetivo:** Convertir el problema de audio en un problema de visi√≥n, permitiendo el uso de CNNs (como ResNet o VGGish) para detectar patrones inaudibles al o√≠do humano.

### 3. Fase de Fusi√≥n: Arquitectura Trimodal üß†
Dise√±o de una red neuronal de tres ramas independientes que convergen en una capa densa final:

```mermaid
graph TD
    subgraph Vision Branch
    A[X-Ray Image] -->|EfficientNet| V[Vector Visual]
    end
    
    subgraph Audio Branch
    B[Cough Audio] -->|STFT + CNN| A_vec[Vector Ac√∫stico]
    end
    
    subgraph NLP Branch
    C[Symptom Text] -->|BERT/RoBERTa| T[Vector Sem√°ntico]
    end
    
    V --> F{Concatenation Layer}
    A_vec --> F
    T --> F
    F --> D[Dense Layers]
    D --> O[Output: COVID Probability]
```
## üöß Estado del Desarrollo (Roadmap)
El notebook documenta el progreso actual del sistema:

[x] Definici√≥n de Arquitectura: Dise√±o conceptual de las 3 ramas y estrategia de fusi√≥n.

[x] Pipeline de NLP: Script de generaci√≥n de datos sint√©ticos completado, funcional y capaz de crear datasets balanceados.

[ ] Pipeline de Audio: Implementaci√≥n de la conversi√≥n a Mel-Spectrograms (En proceso).

[ ] Entrenamiento: Configuraci√≥n del loop de entrenamiento y validaci√≥n cruzada.

## üõ†Ô∏è Stack Tecnol√≥gico
Generative AI: LLM APIs para Data Augmentation.

Deep Learning: PyTorch / TensorFlow (Soporte GPU T4 habilitado).

Audio Processing: Librosa (Extracci√≥n de caracter√≠sticas espectrales).

NLP: Hugging Face Transformers (Tokenizaci√≥n).

Data Ops: Pandas, Tqdm (Control de progreso).

üë• Cr√©ditos
Investigaci√≥n desarrollada para el curso de especializaci√≥n en Inteligencia Artificial (EFE) - Univerisidad Tecnol√≥gica Metropolitana .

Patricio Abarca - https://github.com/Begluckt
Rodrigo Tapia - https://github.com/Chucaflu11
